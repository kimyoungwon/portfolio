---
title: "The Art of Crafting Prompts for Essay Grading with ChatGPT"
excerpt: "Blog2: Automated Essay Scoring with ChatGPT (2024) <br/><img src='/personal_page/images/prompt-engineering.png'>"
date: 2024-06-03
collection: portfolio
---

Blog Objectives
-----
In this blog, our goal is to elucidate how varying prompts affect the grading performance of ChatGPT, offering educators and researchers insights for the use of ChatGPT for grading. By experimenting with a range of prompts, from simple to complex, we aim to provide a better understanding of how to use ChatGPT most effectively in assessing student essays, alongside a comparative analysis of results derived from these diverse prompts.

In this blog we will cover the following variations:

- Scoring ranges: Exploring the effects of providing specific score ranges (e.g., 1-5, 1-7, 1-10).
- Role: Examining how assigning ChatGPT a specific role (e.g., “grader for elementary, college, graduate students”) influences outcomes.
- Scoring criteria: Investigating the influence of providing explicit criteria (e.g., grammar, content, structure) versus leaving it more open.
- Form of outcome: Comparing results when asking for a numerical score, Likert scale rating, or different data structures (e.g., JSON).
- Advanced techniques: Delving into few-shot learning and chain-of-thought reasoning to enhance ChatGPT’s grading capabilities.

Co-authors
-----
- Youngwon Kim (Harvard University)
- Reagan Mozer (Bentley University)
- Luke Miratrix (Harvard University)
- Shireen Al-Adeimi (Michigan State University)

You can see this blog from [this website](https://cares-blog.gse.harvard.edu/post/crafting-prompts/).
